{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Testing Framework\n",
    "\n",
    "This notebook provides a structured approach to:\n",
    "1. Easily enable/disable different feature groups\n",
    "2. Test multiple feature combinations systematically\n",
    "3. Compare performance across different configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n"
     ]
    }
   ],
   "source": [
    "# ===== IMPORTS =====\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations, product\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "# Define random seed\n",
    "seed = 42\n",
    "\n",
    "# Individual Feature Configuration - Set to True/False to enable/disable each feature\n",
    "FEATURE_CONFIG = {\n",
    "    # === ATTRIBUTE FEATURES ===\n",
    "    'attribute_i': True,              # Individual attribute value for node i\n",
    "    'attribute_j': True,              # Individual attribute value for node j\n",
    "    'attribute_equality': True,       # Attribute equality indicator\n",
    "    \n",
    "    # === BASIC NODE FEATURES ===\n",
    "    'degree_i': True,                 # Degree of node i\n",
    "    'degree_j': True,                 # Degree of node j\n",
    "    'clustering_i': True,             # Clustering coefficient of node i\n",
    "    'clustering_j': True,             # Clustering coefficient of node j\n",
    "    'pagerank_i': True,               # PageRank of node i\n",
    "    'pagerank_j': True,               # PageRank of node j\n",
    "    \n",
    "    # === NEIGHBORHOOD FEATURES ===\n",
    "    'common_neighbors': True,         # Number of common neighbors\n",
    "    'jaccard_coefficient': True,      # Jaccard coefficient\n",
    "    'adamic_adar': True,              # Adamic-Adar index\n",
    "    'resource_allocation': True,       # Resource Allocation index\n",
    "    'preferential_attachment': True,   # Preferential Attachment\n",
    "    'salton_index': True,             # Salton index\n",
    "    'sorensen_index': True,           # Sorensen index\n",
    "    'two_hop_neighbors': True,        # 2-hop neighbors count\n",
    "    \n",
    "    # === DERIVED FEATURES ===\n",
    "    'degree_sum': True,               # Sum of degrees\n",
    "    'degree_diff': True,              # Absolute difference of degrees\n",
    "    'degree_product': True,            # Product of degrees\n",
    "    'degree_ratio': True,             # Ratio of degrees (min/max)\n",
    "    'clustering_avg': True,           # Average clustering coefficient\n",
    "    'pagerank_avg': True,             # Average PageRank\n",
    "    \n",
    "    # === COMMUNITY FEATURES (Resolution 1.0) ===\n",
    "    'same_community': True,           # Same community indicator\n",
    "    'community_size_i': True,         # Community size of node i\n",
    "    'community_size_j': True,         # Community size of node j\n",
    "    'community_size_diff': True,      # Absolute difference in community sizes\n",
    "    'community_size_ratio': True,     # Ratio of community sizes\n",
    "    \n",
    "    # === COMMUNITY FEATURES (Resolution 0.5 - Bigger Communities) ===\n",
    "    'same_community_big': True,       # Same community indicator (big communities)\n",
    "    'community_size_i_big': True,     # Community size of node i (big communities)\n",
    "    'community_size_j_big': True,     # Community size of node j (big communities)\n",
    "    'community_size_diff_big': True,  # Absolute difference in community sizes (big communities)\n",
    "    'community_size_ratio_big': True, # Ratio of community sizes (big communities)\n",
    "}\n",
    "\n",
    "# Model Configuration\n",
    "MODEL_CONFIG = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 3,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 3,\n",
    "    'random_state': seed,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Cross-validation Configuration\n",
    "CV_CONFIG = {\n",
    "    'n_splits': 5,\n",
    "    'shuffle': True,\n",
    "    'random_state': seed\n",
    "}\n",
    "\n",
    "# Community Configuration\n",
    "COMMUNITY_CONFIG = {\n",
    "    'resolution_small': 1.0,  # Smaller communities (more granular)\n",
    "    'resolution_big': 0.5,    # Bigger communities (less granular)\n",
    "    'test_resolutions': np.arange(0.3, 2.0, 0.1).tolist()  # For testing multiple resolutions\n",
    "}\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded with 1500 nodes and 6600 edges\n",
      "   ✓ Encoded 'attribute': ['d', 'f', 'l', 'm', 'x', 'y']\n",
      "✓ Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# ===== DATA LOADING =====\n",
    "def load_data():\n",
    "    \"\"\"Load graph and attributes data\"\"\"\n",
    "    # Load graph\n",
    "    path = \"./../assignment2_files_2025/edges_train.edgelist\"\n",
    "    G = nx.read_edgelist(path, delimiter=',', nodetype=int, create_using=nx.Graph())\n",
    "    print(f\"Graph loaded with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "    \n",
    "    # Load attributes\n",
    "    pathattributes = \"./../assignment2_files_2025/attributes.csv\"\n",
    "    attributes_df = pd.read_csv(pathattributes)\n",
    "    node_id_col = attributes_df.columns[0]\n",
    "    attribute_cols = [col for col in attributes_df.columns if col != node_id_col]\n",
    "    \n",
    "    # Encode categorical to numerical\n",
    "    for col in attribute_cols:\n",
    "        if attributes_df[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            attributes_df[col] = le.fit_transform(attributes_df[col].astype(str))\n",
    "            print(f\"   ✓ Encoded '{col}': {list(le.classes_)}\")\n",
    "    \n",
    "    attributes_dict = attributes_df.set_index(node_id_col).to_dict('index')\n",
    "    \n",
    "    return G, attributes_dict, attribute_cols\n",
    "\n",
    "# Load data\n",
    "G, attributes_dict, attribute_cols = load_data()\n",
    "print(\"✓ Data loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature engineering function defined\n",
      "✓ Precomputed metrics helper function defined\n"
     ]
    }
   ],
   "source": [
    "# ===== FEATURE ENGINEERING =====\n",
    "def get_features(G, i, j, feature_config=FEATURE_CONFIG, precomputed_metrics=None):\n",
    "    \"\"\"\n",
    "    Features voor node pair (i, j) based on configuration\n",
    "    Args:\n",
    "        G: NetworkX graph\n",
    "        i, j: Node pair\n",
    "        feature_config: Feature configuration dictionary\n",
    "        precomputed_metrics: Dictionary with precomputed metrics (pa, pagerank, clustering, community_dict, comm_sizes)\n",
    "    Returns: (feature_array, feature_names)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    feature_names = []\n",
    "    \n",
    "    # Get attribute values\n",
    "    attrs_i = attributes_dict.get(i, {})\n",
    "    attrs_j = attributes_dict.get(j, {})\n",
    "    \n",
    "    # --- Attribute features ---\n",
    "    for col in attribute_cols:\n",
    "        val_i = attrs_i.get(col, 0)\n",
    "        val_j = attrs_j.get(col, 0)\n",
    "        \n",
    "        if feature_config['attribute_i']:\n",
    "            features.append(val_i)\n",
    "            feature_names.append(f\"{col}_i\")\n",
    "        \n",
    "        if feature_config['attribute_j']:\n",
    "            features.append(val_j)\n",
    "            feature_names.append(f\"{col}_j\")\n",
    "        \n",
    "        if feature_config['attribute_equality']:\n",
    "            features.append(int(val_i == val_j))\n",
    "            feature_names.append(f\"{col}_eq\")\n",
    "    \n",
    "    # --- Basic node features ---\n",
    "    deg_i = G.degree(i)\n",
    "    deg_j = G.degree(j)\n",
    "    \n",
    "    # Use precomputed metrics if available, otherwise compute on-the-fly\n",
    "    if precomputed_metrics:\n",
    "        cc_i = precomputed_metrics['clustering'].get(i, 0)\n",
    "        cc_j = precomputed_metrics['clustering'].get(j, 0)\n",
    "        pr_i = precomputed_metrics['pagerank'].get(i, 0)\n",
    "        pr_j = precomputed_metrics['pagerank'].get(j, 0)\n",
    "    else:\n",
    "        # Fallback: compute on-the-fly (not recommended for performance)\n",
    "        cc_i = nx.clustering(G, i)\n",
    "        cc_j = nx.clustering(G, j)\n",
    "        pr_i = nx.pagerank(G)[i] if i in nx.pagerank(G) else 0\n",
    "        pr_j = nx.pagerank(G)[j] if j in nx.pagerank(G) else 0\n",
    "    \n",
    "    if feature_config['degree_i']:\n",
    "        features.append(deg_i)\n",
    "        feature_names.append('deg_i')\n",
    "    \n",
    "    if feature_config['degree_j']:\n",
    "        features.append(deg_j)\n",
    "        feature_names.append('deg_j')\n",
    "    \n",
    "    if feature_config['clustering_i']:\n",
    "        features.append(cc_i)\n",
    "        feature_names.append('cc_i')\n",
    "    \n",
    "    if feature_config['clustering_j']:\n",
    "        features.append(cc_j)\n",
    "        feature_names.append('cc_j')\n",
    "    \n",
    "    if feature_config['pagerank_i']:\n",
    "        features.append(pr_i)\n",
    "        feature_names.append('pr_i')\n",
    "    \n",
    "    if feature_config['pagerank_j']:\n",
    "        features.append(pr_j)\n",
    "        feature_names.append('pr_j')\n",
    "    \n",
    "    # --- Neighborhood features ---\n",
    "    common = list(nx.common_neighbors(G, i, j))\n",
    "    cn_ij = len(common)\n",
    "    \n",
    "    if feature_config['common_neighbors']:\n",
    "        features.append(cn_ij)\n",
    "        feature_names.append('cn_ij')\n",
    "    \n",
    "    if feature_config['jaccard_coefficient']:\n",
    "        jc_ij = next(nx.jaccard_coefficient(G, [(i,j)]))[2]\n",
    "        features.append(jc_ij)\n",
    "        feature_names.append('jc_ij')\n",
    "    \n",
    "    if feature_config['adamic_adar']:\n",
    "        aa_ij = sum(1.0 / np.log(G.degree(z)) for z in common if G.degree(z) > 1)\n",
    "        features.append(aa_ij)\n",
    "        feature_names.append('aa_ij')\n",
    "    \n",
    "    if feature_config['resource_allocation']:\n",
    "        ra_ij = sum(1.0 / G.degree(z) for z in common if G.degree(z) > 0)\n",
    "        features.append(ra_ij)\n",
    "        feature_names.append('ra_ij')\n",
    "    \n",
    "    if feature_config['preferential_attachment']:\n",
    "        if precomputed_metrics and 'pa' in precomputed_metrics:\n",
    "            pa_ij = precomputed_metrics['pa'][i, j]\n",
    "        else:\n",
    "            # Fallback: compute on-the-fly (very expensive!)\n",
    "            pa_ij = next(nx.preferential_attachment(G, [(i, j)]))[2]\n",
    "        features.append(pa_ij)\n",
    "        feature_names.append('pa_ij')\n",
    "    \n",
    "    if feature_config['salton_index']:\n",
    "        salton = cn_ij / np.sqrt(deg_i * deg_j) if (deg_i * deg_j) > 0 else 0\n",
    "        features.append(salton)\n",
    "        feature_names.append('salton')\n",
    "    \n",
    "    if feature_config['sorensen_index']:\n",
    "        sorensen = (2 * cn_ij) / (deg_i + deg_j) if (deg_i + deg_j) > 0 else 0\n",
    "        features.append(sorensen)\n",
    "        feature_names.append('sorensen')\n",
    "    \n",
    "    if feature_config['two_hop_neighbors']:\n",
    "        # 2 hop neighbors\n",
    "        dist2_i = set(nx.single_source_shortest_path_length(G, i, cutoff=2))\n",
    "        dist2_j = set(nx.single_source_shortest_path_length(G, j, cutoff=2))\n",
    "        \n",
    "        # remove the nodes themselves and their direct neighbors\n",
    "        dist2_i -= {i} | set(G.neighbors(i))\n",
    "        dist2_j -= {j} | set(G.neighbors(j))\n",
    "        \n",
    "        # intersection of these \"exactly distance-2\" neighborhoods\n",
    "        dist2_count = len(dist2_i & dist2_j)\n",
    "        features.append(dist2_count)\n",
    "        feature_names.append('dist2_count')\n",
    "    \n",
    "    # --- Derived features ---\n",
    "    if feature_config['degree_sum']:\n",
    "        deg_sum = deg_i + deg_j\n",
    "        features.append(deg_sum)\n",
    "        feature_names.append('deg_sum')\n",
    "    \n",
    "    if feature_config['degree_diff']:\n",
    "        deg_diff = abs(deg_i - deg_j)\n",
    "        features.append(deg_diff)\n",
    "        feature_names.append('deg_diff')\n",
    "    \n",
    "    if feature_config['degree_product']:\n",
    "        deg_product = deg_i * deg_j\n",
    "        features.append(deg_product)\n",
    "        feature_names.append('deg_product')\n",
    "    \n",
    "    if feature_config['degree_ratio']:\n",
    "        deg_ratio = min(deg_i, deg_j) / max(deg_i, deg_j) if max(deg_i, deg_j) > 0 else 0\n",
    "        features.append(deg_ratio)\n",
    "        feature_names.append('deg_ratio')\n",
    "    \n",
    "    if feature_config['clustering_avg']:\n",
    "        cc_avg = (cc_i + cc_j) / 2\n",
    "        features.append(cc_avg)\n",
    "        feature_names.append('cc_avg')\n",
    "    \n",
    "    if feature_config['pagerank_avg']:\n",
    "        pr_avg = (pr_i + pr_j) / 2\n",
    "        features.append(pr_avg)\n",
    "        feature_names.append('pr_avg')\n",
    "    \n",
    "    # --- Community features (Small communities) ---\n",
    "    if precomputed_metrics and 'community_dict_small' in precomputed_metrics:\n",
    "        comm_i_small = precomputed_metrics['community_dict_small'].get(i, -1)\n",
    "        comm_j_small = precomputed_metrics['community_dict_small'].get(j, -1)\n",
    "        comm_sizes_small = precomputed_metrics['comm_sizes_small']\n",
    "    else:\n",
    "        # Fallback: compute communities on-the-fly (expensive!)\n",
    "        communities_small = list(nx.algorithms.community.greedy_modularity_communities(G, resolution=COMMUNITY_CONFIG['resolution_small']))\n",
    "        community_dict_small = {n: cid for cid, nodes in enumerate(communities_small) for n in nodes}\n",
    "        comm_sizes_small = {cid: len(nodes) for cid, nodes in enumerate(communities_small)}\n",
    "        comm_i_small = community_dict_small.get(i, -1)\n",
    "        comm_j_small = community_dict_small.get(j, -1)\n",
    "    \n",
    "    if feature_config['same_community']:\n",
    "        same_comm_small = int(comm_i_small == comm_j_small)\n",
    "        features.append(same_comm_small)\n",
    "        feature_names.append('same_comm')\n",
    "    \n",
    "    if feature_config['community_size_i']:\n",
    "        size_i_small = comm_sizes_small.get(comm_i_small, 0)\n",
    "        features.append(size_i_small)\n",
    "        feature_names.append('size_i')\n",
    "    \n",
    "    if feature_config['community_size_j']:\n",
    "        size_j_small = comm_sizes_small.get(comm_j_small, 0)\n",
    "        features.append(size_j_small)\n",
    "        feature_names.append('size_j')\n",
    "    \n",
    "    if feature_config['community_size_diff']:\n",
    "        size_i_small = comm_sizes_small.get(comm_i_small, 0)\n",
    "        size_j_small = comm_sizes_small.get(comm_j_small, 0)\n",
    "        abs_size_diff_small = abs(size_i_small - size_j_small)\n",
    "        features.append(abs_size_diff_small)\n",
    "        feature_names.append('abs_size_diff')\n",
    "    \n",
    "    if feature_config['community_size_ratio']:\n",
    "        size_i_small = comm_sizes_small.get(comm_i_small, 0)\n",
    "        size_j_small = comm_sizes_small.get(comm_j_small, 0)\n",
    "        if size_i_small + size_j_small > 0:\n",
    "            rel_size_ratio_small = size_i_small / (size_j_small + 1e-6)\n",
    "        else:\n",
    "            rel_size_ratio_small = 0\n",
    "        features.append(rel_size_ratio_small)\n",
    "        feature_names.append('rel_size_ratio')\n",
    "    \n",
    "    # --- Community features (Big communities) ---\n",
    "    if precomputed_metrics and 'community_dict_big' in precomputed_metrics:\n",
    "        comm_i_big = precomputed_metrics['community_dict_big'].get(i, -1)\n",
    "        comm_j_big = precomputed_metrics['community_dict_big'].get(j, -1)\n",
    "        comm_sizes_big = precomputed_metrics['comm_sizes_big']\n",
    "    else:\n",
    "        # Fallback: compute communities on-the-fly (expensive!)\n",
    "        communities_big = list(nx.algorithms.community.greedy_modularity_communities(G, resolution=COMMUNITY_CONFIG['resolution_big']))\n",
    "        community_dict_big = {n: cid for cid, nodes in enumerate(communities_big) for n in nodes}\n",
    "        comm_sizes_big = {cid: len(nodes) for cid, nodes in enumerate(communities_big)}\n",
    "        comm_i_big = community_dict_big.get(i, -1)\n",
    "        comm_j_big = community_dict_big.get(j, -1)\n",
    "    \n",
    "    if feature_config['same_community_big']:\n",
    "        same_comm_big = int(comm_i_big == comm_j_big)\n",
    "        features.append(same_comm_big)\n",
    "        feature_names.append('same_comm_big')\n",
    "    \n",
    "    if feature_config['community_size_i_big']:\n",
    "        size_i_big = comm_sizes_big.get(comm_i_big, 0)\n",
    "        features.append(size_i_big)\n",
    "        feature_names.append('size_i_big')\n",
    "    \n",
    "    if feature_config['community_size_j_big']:\n",
    "        size_j_big = comm_sizes_big.get(comm_j_big, 0)\n",
    "        features.append(size_j_big)\n",
    "        feature_names.append('size_j_big')\n",
    "    \n",
    "    if feature_config['community_size_diff_big']:\n",
    "        size_i_big = comm_sizes_big.get(comm_i_big, 0)\n",
    "        size_j_big = comm_sizes_big.get(comm_j_big, 0)\n",
    "        abs_size_diff_big = abs(size_i_big - size_j_big)\n",
    "        features.append(abs_size_diff_big)\n",
    "        feature_names.append('abs_size_diff_big')\n",
    "    \n",
    "    if feature_config['community_size_ratio_big']:\n",
    "        size_i_big = comm_sizes_big.get(comm_i_big, 0)\n",
    "        size_j_big = comm_sizes_big.get(comm_j_big, 0)\n",
    "        if size_i_big + size_j_big > 0:\n",
    "            rel_size_ratio_big = size_i_big / (size_j_big + 1e-6)\n",
    "        else:\n",
    "            rel_size_ratio_big = 0\n",
    "        features.append(rel_size_ratio_big)\n",
    "        feature_names.append('rel_size_ratio_big')\n",
    "    \n",
    "    return np.array(features, dtype=float), feature_names\n",
    "\n",
    "def precompute_metrics(G_train, community_resolution_small=1.0, community_resolution_big=0.5):\n",
    "    \"\"\"\n",
    "    Pre-compute all expensive graph metrics using ONLY training graph\n",
    "    Args:\n",
    "        G_train: NetworkX training graph (only training edges)\n",
    "        community_resolution_small: Resolution parameter for small communities\n",
    "        community_resolution_big: Resolution parameter for big communities\n",
    "    Returns:\n",
    "        Dictionary with precomputed metrics\n",
    "    \"\"\"\n",
    "    N = G_train.number_of_nodes()\n",
    "    \n",
    "    # Preferential Attachment\n",
    "    pa = np.zeros((N, N))\n",
    "    for u, v, p in nx.preferential_attachment(G_train, [(i, j) for i in range(N) for j in range(N)]):\n",
    "        pa[u, v] = p\n",
    "    \n",
    "    # PageRank\n",
    "    pagerank = nx.pagerank(G_train)\n",
    "    \n",
    "    # Clustering        \n",
    "    clustering = nx.clustering(G_train)\n",
    "    \n",
    "    # Small Communities (more granular)\n",
    "    communities_small = list(nx.algorithms.community.greedy_modularity_communities(G_train, resolution=community_resolution_small))\n",
    "    community_dict_small = {n: cid for cid, nodes in enumerate(communities_small) for n in nodes}\n",
    "    comm_sizes_small = {cid: len(nodes) for cid, nodes in enumerate(communities_small)}\n",
    "    \n",
    "    # Big Communities (less granular)\n",
    "    communities_big = list(nx.algorithms.community.greedy_modularity_communities(G_train, resolution=community_resolution_big))\n",
    "    community_dict_big = {n: cid for cid, nodes in enumerate(communities_big) for n in nodes}\n",
    "    comm_sizes_big = {cid: len(nodes) for cid, nodes in enumerate(communities_big)}\n",
    "    \n",
    "    return {\n",
    "        'pa': pa,\n",
    "        'pagerank': pagerank,\n",
    "        'clustering': clustering,\n",
    "        'community_dict_small': community_dict_small,\n",
    "        'comm_sizes_small': comm_sizes_small,\n",
    "        'community_dict_big': community_dict_big,\n",
    "        'comm_sizes_big': comm_sizes_big\n",
    "    }\n",
    "\n",
    "print(\"✓ Feature engineering function defined\")\n",
    "print(\"✓ Precomputed metrics helper function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Single configuration testing function defined\n"
     ]
    }
   ],
   "source": [
    "# ===== SINGLE CONFIGURATION TESTING =====\n",
    "def test_single_configuration(feature_config, model_config=MODEL_CONFIG, cv_config=CV_CONFIG, \n",
    "                            community_resolution_small=1.0, community_resolution_big=0.5):\n",
    "    \"\"\"Test a single feature configuration\"\"\"\n",
    "    print(f\"\\n=== Testing Configuration ===\")\n",
    "    print(f\"Enabled features: {[k for k, v in feature_config.items() if v]}\")\n",
    "    \n",
    "    # Initialize results\n",
    "    auc_scores = []\n",
    "    acc_scores = []\n",
    "    \n",
    "    # K-fold cross validation\n",
    "    edges = np.array(list(G.edges()))\n",
    "    kf = KFold(n_splits=cv_config['n_splits'], shuffle=cv_config['shuffle'], random_state=cv_config['random_state'])\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(edges), 1):\n",
    "        print(f\"\\n--- Fold {fold} ---\")\n",
    "        \n",
    "        # Split edges\n",
    "        train_edges = edges[train_idx]\n",
    "        val_edges = edges[val_idx]\n",
    "        \n",
    "        # Build training graph\n",
    "        G_train = nx.Graph()\n",
    "        G_train.add_nodes_from(G.nodes())\n",
    "        G_train.add_edges_from(train_edges)\n",
    "        \n",
    "        # Pre-compute metrics using helper function\n",
    "        precomputed_metrics = precompute_metrics(G_train, community_resolution_small, community_resolution_big)\n",
    "        \n",
    "        # Build training data\n",
    "        pos_train = train_edges\n",
    "        rng = np.random.default_rng(seed)\n",
    "        non_edges = np.array(list(nx.non_edges(G_train)))\n",
    "        neg_train = non_edges[rng.choice(len(non_edges), size=len(pos_train), replace=False)]\n",
    "        \n",
    "        X_train_features = []\n",
    "        for (u, v) in np.vstack([pos_train, neg_train]):\n",
    "            feat, _ = get_features(G_train, u, v, feature_config, precomputed_metrics)\n",
    "            X_train_features.append(feat)\n",
    "        \n",
    "        y_train = [1]*len(pos_train) + [0]*len(neg_train)\n",
    "    \n",
    "        # Build validation data\n",
    "        pos_val = val_edges\n",
    "        rng2 = np.random.default_rng(seed+1)\n",
    "        non_edges = np.array(list(nx.non_edges(G_train)))\n",
    "        neg_val = non_edges[rng2.choice(len(non_edges), size=len(pos_val), replace=False)]\n",
    "        \n",
    "        X_val_features = []\n",
    "        for (u, v) in np.vstack([pos_val, neg_val]):\n",
    "            feat, _ = get_features(G_train, u, v, feature_config, precomputed_metrics)\n",
    "            X_val_features.append(feat)\n",
    "        \n",
    "        y_val = [1]*len(pos_val) + [0]*len(neg_val)\n",
    "    \n",
    "        # Train model\n",
    "        clf = RandomForestClassifier(**model_config)\n",
    "        clf.fit(X_train_features, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred_proba = clf.predict_proba(X_val_features)[:,1]\n",
    "        auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        auc_scores.append(auc)\n",
    "        \n",
    "        y_pred_val = clf.predict(X_val_features)\n",
    "        val_acc = accuracy_score(y_val, y_pred_val)\n",
    "        acc_scores.append(val_acc)\n",
    "        \n",
    "        print(f\"Fold {fold} AUC: {auc:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # Calculate final results\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    std_auc = np.std(auc_scores)\n",
    "    mean_acc = np.mean(acc_scores)\n",
    "    std_acc = np.std(acc_scores)\n",
    "    \n",
    "    print(f\"\\n=== Results ===\")\n",
    "    print(f\"Mean AUC: {mean_auc:.4f} ± {std_auc:.4f}\")\n",
    "    print(f\"Mean Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'mean_auc': mean_auc,\n",
    "        'std_auc': std_auc,\n",
    "        'mean_acc': mean_acc,\n",
    "        'std_acc': std_acc,\n",
    "        'auc_scores': auc_scores,\n",
    "        'acc_scores': acc_scores\n",
    "    }\n",
    "\n",
    "print(\"✓ Single configuration testing function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Individual feature testing functions defined\n",
      "✓ Community resolution testing function defined\n",
      "✓ Community feature comparison function defined\n"
     ]
    }
   ],
   "source": [
    "# ===== INDIVIDUAL FEATURE TESTING =====\n",
    "def test_individual_features(max_features=10):\n",
    "    \"\"\"Test individual features to identify the most important ones\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Test each individual feature\n",
    "    print(\"\\n=== Testing Individual Features ===\")\n",
    "    for feature_name in FEATURE_CONFIG.keys():\n",
    "        config = {key: False for key in FEATURE_CONFIG.keys()}\n",
    "        config[feature_name] = True\n",
    "        \n",
    "        print(f\"\\nTesting {feature_name}...\")\n",
    "        result = test_single_configuration(config)\n",
    "        result['config_name'] = feature_name\n",
    "        result['features'] = [feature_name]\n",
    "        results.append(result)\n",
    "    \n",
    "    # Sort by AUC to find best individual features\n",
    "    results.sort(key=lambda x: x['mean_auc'], reverse=True)\n",
    "    \n",
    "    # Test combinations of top features\n",
    "    print(\"\\n=== Testing Top Feature Combinations ===\")\n",
    "    top_features = [r['config_name'] for r in results[:max_features]]\n",
    "    \n",
    "    # Test all combinations of 2 top features\n",
    "    for combo in combinations(top_features, 2):\n",
    "        config = {key: False for key in FEATURE_CONFIG.keys()}\n",
    "        config_name = f\"{combo[0]} + {combo[1]}\"\n",
    "        \n",
    "        for feature in combo:\n",
    "            config[feature] = True\n",
    "        \n",
    "        print(f\"\\nTesting {config_name}...\")\n",
    "        result = test_single_configuration(config)\n",
    "        result['config_name'] = config_name\n",
    "        result['features'] = list(combo)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Test all features\n",
    "    print(\"\\n=== Testing All Features ===\")\n",
    "    config = {key: True for key in FEATURE_CONFIG.keys()}\n",
    "    result = test_single_configuration(config)\n",
    "    result['config_name'] = 'all_features'\n",
    "    result['features'] = list(FEATURE_CONFIG.keys())\n",
    "    results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ===== FEATURE GROUP TESTING =====\n",
    "def test_feature_groups():\n",
    "    \"\"\"Test logical feature groups for systematic analysis\"\"\"\n",
    "    # Define logical feature groups\n",
    "    feature_groups = {\n",
    "        'attributes': ['attribute_i', 'attribute_j', 'attribute_equality'],\n",
    "        'basic_node': ['degree_i', 'degree_j', 'clustering_i', 'clustering_j', 'pagerank_i', 'pagerank_j'],\n",
    "        'neighborhood': ['common_neighbors', 'jaccard_coefficient', 'adamic_adar', \n",
    "                        'resource_allocation', 'preferential_attachment', \n",
    "                        'salton_index', 'sorensen_index', 'two_hop_neighbors'],\n",
    "        'derived': ['degree_sum', 'degree_diff', 'degree_product', 'degree_ratio', \n",
    "                   'clustering_avg', 'pagerank_avg'],\n",
    "        'community': ['same_community', 'community_size_i', 'community_size_j', \n",
    "                     'community_size_diff', 'community_size_ratio']\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test individual groups\n",
    "    print(\"\\n=== Testing Feature Groups ===\")\n",
    "    for group_name, features in feature_groups.items():\n",
    "        config = {key: False for key in FEATURE_CONFIG.keys()}\n",
    "        for feature in features:\n",
    "            config[feature] = True\n",
    "        \n",
    "        print(f\"\\nTesting {group_name} group...\")\n",
    "        result = test_single_configuration(config)\n",
    "        result['config_name'] = group_name\n",
    "        result['features'] = features\n",
    "        results.append(result)\n",
    "    \n",
    "    # Test some combinations\n",
    "    print(\"\\n=== Testing Group Combinations ===\")\n",
    "    group_names = list(feature_groups.keys())\n",
    "    \n",
    "    # Test all combinations of 2 groups\n",
    "    for combo in combinations(group_names, 2):\n",
    "        config = {key: False for key in FEATURE_CONFIG.keys()}\n",
    "        config_name = f\"{' + '.join(combo)}\"\n",
    "        \n",
    "        for group in combo:\n",
    "            for feature in feature_groups[group]:\n",
    "                config[feature] = True\n",
    "        \n",
    "        print(f\"\\nTesting {config_name}...\")\n",
    "        result = test_single_configuration(config)\n",
    "        result['config_name'] = config_name\n",
    "        result['features'] = [f for group in combo for f in feature_groups[group]]\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ===== COMMUNITY RESOLUTION TESTING =====\n",
    "def test_community_resolutions(feature_config=None, resolution_pairs=None):\n",
    "    \"\"\"\n",
    "    Test different combinations of community resolutions\n",
    "    Args:\n",
    "        feature_config: Feature configuration (if None, uses only community features)\n",
    "        resolution_pairs: List of (small_resolution, big_resolution) tuples to test\n",
    "    \"\"\"\n",
    "    if feature_config is None:\n",
    "        # Default: only community features\n",
    "        feature_config = {key: False for key in FEATURE_CONFIG.keys()}\n",
    "        # Enable all community features\n",
    "        community_features = [k for k in FEATURE_CONFIG.keys() if 'community' in k]\n",
    "        for feat in community_features:\n",
    "            feature_config[feat] = True\n",
    "    \n",
    "    if resolution_pairs is None:\n",
    "        # Default resolution pairs to test\n",
    "        resolution_pairs = [\n",
    "            (1.2, 1.0),   # Medium+ big\n",
    "            (1.4, 1.0),   # Medium big\n",
    "            (1.6, 1.0),   # Avg big\n",
    "            (1.8, 1.0),   # Smaller big\n",
    "            (2.0, 1.0),   # Small big\n",
    "            (2.2, 1.0),   # Smallest big\n",
    "        ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\n=== Testing Community Resolution Combinations ===\")\n",
    "    print(f\"Feature config: {[k for k, v in feature_config.items() if v]}\")\n",
    "    \n",
    "    for small_res, big_res in resolution_pairs:\n",
    "        print(f\"\\n--- Testing resolutions: small={small_res}, big={big_res} ---\")\n",
    "        \n",
    "        result = test_single_configuration(\n",
    "            feature_config, \n",
    "            community_resolution_small=small_res, \n",
    "            community_resolution_big=big_res\n",
    "        )\n",
    "        \n",
    "        result['config_name'] = f\"small_{small_res}_big_{big_res}\"\n",
    "        result['small_resolution'] = small_res\n",
    "        result['big_resolution'] = big_res\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ===== COMPARE SMALL VS BIG COMMUNITY FEATURES =====\n",
    "def compare_community_features():\n",
    "    \"\"\"Compare small community features vs big community features\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Test 1: Only small community features\n",
    "    small_config = {key: False for key in FEATURE_CONFIG.keys()}\n",
    "    small_features = [k for k in FEATURE_CONFIG.keys() if 'community' in k and 'big' not in k]\n",
    "    for feat in small_features:\n",
    "        small_config[feat] = True\n",
    "    \n",
    "    print(\"\\n=== Testing Small Community Features Only ===\")\n",
    "    result = test_single_configuration(small_config)\n",
    "    result['config_name'] = 'small_communities_only'\n",
    "    result['features'] = small_features\n",
    "    results.append(result)\n",
    "    \n",
    "    # Test 2: Only big community features\n",
    "    big_config = {key: False for key in FEATURE_CONFIG.keys()}\n",
    "    big_features = [k for k in FEATURE_CONFIG.keys() if 'community' in k and 'big' in k]\n",
    "    for feat in big_features:\n",
    "        big_config[feat] = True\n",
    "    \n",
    "    print(\"\\n=== Testing Big Community Features Only ===\")\n",
    "    result = test_single_configuration(big_config)\n",
    "    result['config_name'] = 'big_communities_only'\n",
    "    result['features'] = big_features\n",
    "    results.append(result)\n",
    "    \n",
    "    # Test 3: Both small and big community features\n",
    "    both_config = {key: False for key in FEATURE_CONFIG.keys()}\n",
    "    all_community_features = [k for k in FEATURE_CONFIG.keys() if 'community' in k]\n",
    "    for feat in all_community_features:\n",
    "        both_config[feat] = True\n",
    "    \n",
    "    print(\"\\n=== Testing Both Small and Big Community Features ===\")\n",
    "    result = test_single_configuration(both_config)\n",
    "    result['config_name'] = 'both_communities'\n",
    "    result['features'] = all_community_features\n",
    "    results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✓ Individual feature testing functions defined\")\n",
    "print(\"✓ Community resolution testing function defined\")\n",
    "print(\"✓ Community feature comparison function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Results analysis function defined\n"
     ]
    }
   ],
   "source": [
    "# ===== RESULTS ANALYSIS =====\n",
    "def analyze_results(results):\n",
    "    \"\"\"Analyze and visualize results from feature testing\"\"\"\n",
    "    # Create results DataFrame\n",
    "    df_results = pd.DataFrame([\n",
    "        {\n",
    "            'config_name': r['config_name'],\n",
    "            'mean_auc': r['mean_auc'],\n",
    "            'std_auc': r['std_auc'],\n",
    "            'mean_acc': r['mean_acc'],\n",
    "            'std_acc': r['std_acc'],\n",
    "            'num_features': len(r['features'])\n",
    "        }\n",
    "        for r in results\n",
    "    ])\n",
    "    \n",
    "    # Sort by AUC\n",
    "    df_results = df_results.sort_values('mean_auc', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== RESULTS SUMMARY ===\")\n",
    "    print(df_results.to_string(index=False))\n",
    "    \n",
    "    # Plot results\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # AUC plot\n",
    "    x_pos = range(len(df_results))\n",
    "    ax1.bar(x_pos, df_results['mean_auc'], yerr=df_results['std_auc'], \n",
    "            capsize=5, alpha=0.7, color='skyblue')\n",
    "    ax1.set_xlabel('Configuration')\n",
    "    ax1.set_ylabel('AUC Score')\n",
    "    ax1.set_title('AUC Scores by Feature Configuration')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(df_results['config_name'], rotation=45, ha='right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax2.bar(x_pos, df_results['mean_acc'], yerr=df_results['std_acc'], \n",
    "            capsize=5, alpha=0.7, color='lightcoral')\n",
    "    ax2.set_xlabel('Configuration')\n",
    "    ax2.set_ylabel('Accuracy Score')\n",
    "    ax2.set_title('Accuracy Scores by Feature Configuration')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(df_results['config_name'], rotation=45, ha='right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature count vs performance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df_results['num_features'], df_results['mean_auc'], \n",
    "                s=100, alpha=0.7, c='blue', label='AUC')\n",
    "    plt.scatter(df_results['num_features'], df_results['mean_acc'], \n",
    "                s=100, alpha=0.7, c='red', label='Accuracy')\n",
    "    plt.xlabel('Number of Features')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Performance vs Number of Features')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "print(\"✓ Results analysis function defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "### 1. Test Current Configuration\n",
    "Run this to test the current individual feature configuration defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Configuration ===\n",
      "Enabled features: ['attribute_i', 'attribute_j', 'attribute_equality', 'degree_i', 'degree_j', 'clustering_i', 'clustering_j', 'pagerank_i', 'pagerank_j', 'common_neighbors', 'jaccard_coefficient', 'adamic_adar', 'resource_allocation', 'preferential_attachment', 'salton_index', 'sorensen_index', 'two_hop_neighbors', 'degree_sum', 'degree_diff', 'degree_product', 'degree_ratio', 'clustering_avg', 'pagerank_avg', 'same_community', 'community_size_i', 'community_size_j', 'community_size_diff', 'community_size_ratio', 'same_community_big', 'community_size_i_big', 'community_size_j_big', 'community_size_diff_big', 'community_size_ratio_big']\n",
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 AUC: 0.9269, Accuracy: 0.8833\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 AUC: 0.9304, Accuracy: 0.8814\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 AUC: 0.9309, Accuracy: 0.8867\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 AUC: 0.9293, Accuracy: 0.8852\n",
      "\n",
      "--- Fold 5 ---\n",
      "Fold 5 AUC: 0.9317, Accuracy: 0.8845\n",
      "\n",
      "=== Results ===\n",
      "Mean AUC: 0.9299 ± 0.0017\n",
      "Mean Accuracy: 0.8842 ± 0.0018\n",
      "\n",
      "Current configuration performance:\n",
      "AUC: 0.9299 ± 0.0017\n",
      "Accuracy: 0.8842 ± 0.0018\n"
     ]
    }
   ],
   "source": [
    "# Test current configuration\n",
    "current_result = test_single_configuration(FEATURE_CONFIG)\n",
    "print(f\"\\nCurrent configuration performance:\")\n",
    "print(f\"AUC: {current_result['mean_auc']:.4f} ± {current_result['std_auc']:.4f}\")\n",
    "print(f\"Accuracy: {current_result['mean_acc']:.4f} ± {current_result['std_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test Individual Features\n",
    "Run this to test each feature individually and find the most important ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test individual features to find the most important ones\n",
    "# results = test_individual_features(max_features=8)\n",
    "# df_results = analyze_results(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test Feature Groups\n",
    "Run this to test logical feature groups and their combinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test feature groups and their combinations\n",
    "# group_results = test_feature_groups()\n",
    "# df_group_results = analyze_results(group_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Custom Individual Feature Configuration\n",
    "Modify the configuration below to test specific individual features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Configuration ===\n",
      "Enabled features: ['attribute_equality', 'two_hop_neighbors', 'degree_diff', 'same_community']\n",
      "\n",
      "--- Fold 1 ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'same_community_big'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 43\u001b[0m\n\u001b[0;32m      2\u001b[0m custom_config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# === ATTRIBUTE FEATURES ===\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattribute_i\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,              \u001b[38;5;66;03m# Individual attribute value for node i\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommunity_size_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,     \u001b[38;5;66;03m# Disable community size ratio\u001b[39;00m\n\u001b[0;32m     40\u001b[0m }\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Test custom configuration\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m custom_result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_single_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCustom configuration performance:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcustom_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_auc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcustom_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_auc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m, in \u001b[0;36mtest_single_configuration\u001b[1;34m(feature_config, model_config, cv_config, community_resolution_small, community_resolution_big)\u001b[0m\n\u001b[0;32m     37\u001b[0m X_train_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (u, v) \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack([pos_train, neg_train]):\n\u001b[1;32m---> 39\u001b[0m     feat, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecomputed_metrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     X_train_features\u001b[38;5;241m.\u001b[39mappend(feat)\n\u001b[0;32m     42\u001b[0m y_train \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(pos_train) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(neg_train)\n",
      "Cell \u001b[1;32mIn[3], line 222\u001b[0m, in \u001b[0;36mget_features\u001b[1;34m(G, i, j, feature_config, precomputed_metrics)\u001b[0m\n\u001b[0;32m    219\u001b[0m     comm_i_big \u001b[38;5;241m=\u001b[39m community_dict_big\u001b[38;5;241m.\u001b[39mget(i, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    220\u001b[0m     comm_j_big \u001b[38;5;241m=\u001b[39m community_dict_big\u001b[38;5;241m.\u001b[39mget(j, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfeature_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame_community_big\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m    223\u001b[0m     same_comm_big \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(comm_i_big \u001b[38;5;241m==\u001b[39m comm_j_big)\n\u001b[0;32m    224\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(same_comm_big)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'same_community_big'"
     ]
    }
   ],
   "source": [
    "# Custom configuration - modify individual features as needed\n",
    "custom_config = {\n",
    "    # === ATTRIBUTE FEATURES ===\n",
    "    'attribute_i': False,              # Individual attribute value for node i\n",
    "    'attribute_j': False,               # Individual attribute value for node j\n",
    "    'attribute_equality': True,       # Disable attribute equality\n",
    "    \n",
    "    # === BASIC NODE FEATURES ===\n",
    "    'degree_i': False,                  # Degree of node i\n",
    "    'degree_j': False,                  # Degree of node j\n",
    "    'clustering_i': False,             # Disable clustering for node i\n",
    "    'clustering_j': False,             # Disable clustering for node j\n",
    "    'pagerank_i': False,                # PageRank of node i\n",
    "    'pagerank_j': False,                # PageRank of node j\n",
    "    \n",
    "    # === NEIGHBORHOOD FEATURES ===\n",
    "    'common_neighbors': False,          # Number of common neighbors\n",
    "    'jaccard_coefficient': False,       # Jaccard coefficient\n",
    "    'adamic_adar': False,              # Disable Adamic-Adar\n",
    "    'resource_allocation': False,        # Resource Allocation index\n",
    "    'preferential_attachment': False,   # Preferential Attachment\n",
    "    'salton_index': False,             # Disable Salton index\n",
    "    'sorensen_index': False,             # Sorensen index\n",
    "    'two_hop_neighbors': True,        # Disable 2-hop neighbors\n",
    "    \n",
    "    # === DERIVED FEATURES ===\n",
    "    'degree_sum': False,                # Sum of degrees\n",
    "    'degree_diff': True,               # Absolute difference of degrees\n",
    "    'degree_product': False,             # Product of degrees\n",
    "    'degree_ratio': False,              # Ratio of degrees\n",
    "    'clustering_avg': False,           # Disable average clustering\n",
    "    'pagerank_avg': False,             # Disable average PageRank\n",
    "    \n",
    "    # === COMMUNITY FEATURES ===\n",
    "    'same_community': True,             # Same community indicator\n",
    "    'community_size_i': False,           # Community size of node i\n",
    "    'community_size_j': False,           # Community size of node j\n",
    "    'community_size_diff': False,        # Absolute difference in community sizes\n",
    "    'community_size_ratio': False,     # Disable community size ratio\n",
    "\n",
    "    # === COMMUNITY FEATURES (Resolution 0.5 - Bigger Communities) ===\n",
    "    'same_community_big': True,       # Same community indicator (big communities)\n",
    "    'community_size_i_big': False,     # Community size of node i (big communities)\n",
    "    'community_size_j_big': False,     # Community size of node j (big communities)\n",
    "    'community_size_diff_big': False,  # Absolute difference in community sizes (big communities)\n",
    "    'community_size_ratio_big': False, # Ratio of community sizes (big communities)\n",
    "}\n",
    "\n",
    "# Test custom configuration\n",
    "custom_result = test_single_configuration(custom_config)\n",
    "print(f\"\\nCustom configuration performance:\")\n",
    "print(f\"AUC: {custom_result['mean_auc']:.4f} ± {custom_result['std_auc']:.4f}\")\n",
    "print(f\"Accuracy: {custom_result['mean_acc']:.4f} ± {custom_result['std_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom configuration - modify individual features as needed\n",
    "custom_config = {\n",
    "    # === ATTRIBUTE FEATURES ===\n",
    "    'attribute_i': False,              # Individual attribute value for node i\n",
    "    'attribute_j': False,               # Individual attribute value for node j\n",
    "    'attribute_equality': True,       # Disable attribute equality\n",
    "    \n",
    "    # === BASIC NODE FEATURES ===\n",
    "    'degree_i': False,                  # Degree of node i\n",
    "    'degree_j': False,                  # Degree of node j\n",
    "    'clustering_i': False,             # Disable clustering for node i\n",
    "    'clustering_j': False,             # Disable clustering for node j\n",
    "    'pagerank_i': False,                # PageRank of node i\n",
    "    'pagerank_j': False,                # PageRank of node j\n",
    "    \n",
    "    # === NEIGHBORHOOD FEATURES ===\n",
    "    'common_neighbors': False,          # Number of common neighbors\n",
    "    'jaccard_coefficient': False,       # Jaccard coefficient\n",
    "    'adamic_adar': False,              # Disable Adamic-Adar\n",
    "    'resource_allocation': False,        # Resource Allocation index\n",
    "    'preferential_attachment': False,   # Preferential Attachment\n",
    "    'salton_index': False,             # Disable Salton index\n",
    "    'sorensen_index': False,             # Sorensen index\n",
    "    'two_hop_neighbors': True,        # Disable 2-hop neighbors\n",
    "    \n",
    "    # === DERIVED FEATURES ===\n",
    "    'degree_sum': False,                # Sum of degrees\n",
    "    'degree_diff': True,               # Absolute difference of degrees\n",
    "    'degree_product': False,             # Product of degrees\n",
    "    'degree_ratio': False,              # Ratio of degrees\n",
    "    'clustering_avg': False,           # Disable average clustering\n",
    "    'pagerank_avg': False,             # Disable average PageRank\n",
    "    \n",
    "    # === COMMUNITY FEATURES ===\n",
    "    'same_community': True,             # Same community indicator\n",
    "    'community_size_i': False,           # Community size of node i\n",
    "    'community_size_j': False,           # Community size of node j\n",
    "    'community_size_diff': False,        # Absolute difference in community sizes\n",
    "    'community_size_ratio': True,     # Disable community size ratio\n",
    "}\n",
    "\n",
    "# Test custom configuration\n",
    "custom_result = test_single_configuration(custom_config)\n",
    "print(f\"\\nCustom configuration performance:\")\n",
    "print(f\"AUC: {custom_result['mean_auc']:.4f} ± {custom_result['std_auc']:.4f}\")\n",
    "print(f\"Accuracy: {custom_result['mean_acc']:.4f} ± {custom_result['std_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate Predictions for Best Configuration\n",
    "Use this to generate predictions for Kaggle submission with the best individual feature configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for best configuration\n",
    "def generate_predictions(best_config, output_filename='predictions_best_config.csv'):\n",
    "    \"\"\"\n",
    "    Generate predictions using the best individual feature configuration\n",
    "    NOTE: This function trains on ALL available training data (no cross-validation)\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Generating Predictions with Best Configuration ===\")\n",
    "    \n",
    "    # Load test data\n",
    "    inpTest = pd.read_csv('./../assignment2_files_2025/solutionInput.csv', sep=',', index_col='ID')\n",
    "    \n",
    "    # Use ALL training edges for final model (this is the correct approach for Kaggle)\n",
    "    edges = np.array(list(G.edges()))\n",
    "    pos_edges = edges\n",
    "    rng = np.random.default_rng(seed)\n",
    "    non_edges = np.array(list(nx.non_edges(G)))\n",
    "    neg_edges = non_edges[rng.choice(len(non_edges), size=len(pos_edges), replace=False)]\n",
    "    \n",
    "    # Pre-compute metrics on the FULL training graph (this is correct for final submission)\n",
    "    precomputed_metrics = precompute_metrics(G, COMMUNITY_CONFIG['resolution_small'], COMMUNITY_CONFIG['resolution_big'])\n",
    "    \n",
    "    # Generate features for training data\n",
    "    X_train = []\n",
    "    for (u, v) in np.vstack([pos_edges, neg_edges]):\n",
    "        feat, _ = get_features(G, u, v, best_config, precomputed_metrics)\n",
    "        X_train.append(feat)\n",
    "    \n",
    "    y_train = [1]*len(pos_edges) + [0]*len(neg_edges)\n",
    "    \n",
    "    # Train model\n",
    "    clf = RandomForestClassifier(**MODEL_CONFIG)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate features for test data (using same precomputed metrics)\n",
    "    test_features = []\n",
    "    for _, row in inpTest.iterrows():\n",
    "        feat, _ = get_features(G, int(row.iloc[0]), int(row.iloc[1]), best_config, precomputed_metrics)\n",
    "        test_features.append(feat)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = clf.predict(test_features)\n",
    "    \n",
    "    # Save predictions\n",
    "    sub = pd.DataFrame({'ID': inpTest.index, 'prediction': predictions})\n",
    "    sub.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"✅ Predictions saved to {output_filename}\")\n",
    "    return clf, test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test Community Resolution Combinations\n",
    "Explore different combinations of small and big community resolutions to find the optimal pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Community Resolution Combinations ===\n",
      "\n",
      "=== Testing Community Resolution Combinations ===\n",
      "Feature config: ['same_community', 'same_community_big']\n",
      "\n",
      "--- Testing resolutions: small=0.6, big=1.5 ---\n",
      "\n",
      "=== Testing Configuration ===\n",
      "Enabled features: ['same_community', 'same_community_big']\n",
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 AUC: 0.8858, Accuracy: 0.8818\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 AUC: 0.8936, Accuracy: 0.8807\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 AUC: 0.8938, Accuracy: 0.8856\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 AUC: 0.8945, Accuracy: 0.8860\n",
      "\n",
      "--- Fold 5 ---\n",
      "Fold 5 AUC: 0.8928, Accuracy: 0.8879\n",
      "\n",
      "=== Results ===\n",
      "Mean AUC: 0.8921 ± 0.0032\n",
      "Mean Accuracy: 0.8844 ± 0.0027\n",
      "\n",
      "--- Testing resolutions: small=0.6, big=2.0 ---\n",
      "\n",
      "=== Testing Configuration ===\n",
      "Enabled features: ['same_community', 'same_community_big']\n",
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 AUC: 0.8882, Accuracy: 0.8837\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 AUC: 0.8932, Accuracy: 0.8792\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 AUC: 0.8943, Accuracy: 0.8845\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 AUC: 0.8945, Accuracy: 0.8845\n",
      "\n",
      "--- Fold 5 ---\n",
      "Fold 5 AUC: 0.8925, Accuracy: 0.8864\n",
      "\n",
      "=== Results ===\n",
      "Mean AUC: 0.8925 ± 0.0023\n",
      "Mean Accuracy: 0.8836 ± 0.0024\n",
      "\n",
      "--- Testing resolutions: small=0.6, big=2.5 ---\n",
      "\n",
      "=== Testing Configuration ===\n",
      "Enabled features: ['same_community', 'same_community_big']\n",
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 AUC: 0.8832, Accuracy: 0.8811\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 AUC: 0.8909, Accuracy: 0.8564\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 AUC: 0.8914, Accuracy: 0.8614\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 AUC: 0.8940, Accuracy: 0.8697\n",
      "\n",
      "--- Fold 5 ---\n",
      "Fold 5 AUC: 0.8911, Accuracy: 0.8742\n",
      "\n",
      "=== Results ===\n",
      "Mean AUC: 0.8901 ± 0.0037\n",
      "Mean Accuracy: 0.8686 ± 0.0088\n",
      "\n",
      "--- Testing resolutions: small=0.6, big=3.0 ---\n",
      "\n",
      "=== Testing Configuration ===\n",
      "Enabled features: ['same_community', 'same_community_big']\n",
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 AUC: 0.8842, Accuracy: 0.8803\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 AUC: 0.8882, Accuracy: 0.8667\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 AUC: 0.8897, Accuracy: 0.8655\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 AUC: 0.8946, Accuracy: 0.8693\n",
      "\n",
      "--- Fold 5 ---\n",
      "Fold 5 AUC: 0.8878, Accuracy: 0.8648\n",
      "\n",
      "=== Results ===\n",
      "Mean AUC: 0.8889 ± 0.0034\n",
      "Mean Accuracy: 0.8693 ± 0.0057\n",
      "\n",
      "--- Testing resolutions: small=0.6, big=3.5 ---\n",
      "\n",
      "=== Testing Configuration ===\n",
      "Enabled features: ['same_community', 'same_community_big']\n",
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 AUC: 0.8836, Accuracy: 0.8777\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 AUC: 0.8843, Accuracy: 0.8663\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 AUC: 0.8753, Accuracy: 0.8659\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 AUC: 0.8879, Accuracy: 0.8693\n",
      "\n",
      "--- Fold 5 ---\n",
      "Fold 5 AUC: 0.8832, Accuracy: 0.8648\n",
      "\n",
      "=== Results ===\n",
      "Mean AUC: 0.8828 ± 0.0041\n",
      "Mean Accuracy: 0.8688 ± 0.0047\n",
      "\n",
      "--- Testing resolutions: small=0.6, big=4.0 ---\n",
      "\n",
      "=== Testing Configuration ===\n",
      "Enabled features: ['same_community', 'same_community_big']\n",
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 AUC: 0.8789, Accuracy: 0.8750\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 AUC: 0.8783, Accuracy: 0.8667\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 AUC: 0.8731, Accuracy: 0.8667\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 AUC: 0.8799, Accuracy: 0.8693\n",
      "\n",
      "--- Fold 5 ---\n"
     ]
    }
   ],
   "source": [
    "# Test different community resolution combinations\n",
    "print(\"=== Testing Community Resolution Combinations ===\")\n",
    "\n",
    "# # Test 1: Only community features with different resolutions\n",
    "# community_only_results = test_community_resolutions(resolution_pairs=pairs)\n",
    "# df_community_results = analyze_results(community_only_results)\n",
    "\n",
    "# Test 2: Community features + some basic features\n",
    "custom_config = {\n",
    "    # === ATTRIBUTE FEATURES ===\n",
    "    'attribute_i': False,              # Individual attribute value for node i\n",
    "    'attribute_j': False,               # Individual attribute value for node j\n",
    "    'attribute_equality': False,       # Disable attribute equality\n",
    "    \n",
    "    # === BASIC NODE FEATURES ===\n",
    "    'degree_i': False,                  # Degree of node i\n",
    "    'degree_j': False,                  # Degree of node j\n",
    "    'clustering_i': False,             # Disable clustering for node i\n",
    "    'clustering_j': False,             # Disable clustering for node j\n",
    "    'pagerank_i': False,                # PageRank of node i\n",
    "    'pagerank_j': False,                # PageRank of node j\n",
    "    \n",
    "    # === NEIGHBORHOOD FEATURES ===\n",
    "    'common_neighbors': False,          # Number of common neighbors\n",
    "    'jaccard_coefficient': False,       # Jaccard coefficient\n",
    "    'adamic_adar': False,              # Disable Adamic-Adar\n",
    "    'resource_allocation': False,        # Resource Allocation index\n",
    "    'preferential_attachment': False,   # Preferential Attachment\n",
    "    'salton_index': False,             # Disable Salton index\n",
    "    'sorensen_index': False,             # Sorensen index\n",
    "    'two_hop_neighbors': False,        # Disable 2-hop neighbors\n",
    "    \n",
    "    # === DERIVED FEATURES ===\n",
    "    'degree_sum': False,                # Sum of degrees\n",
    "    'degree_diff': False,               # Absolute difference of degrees\n",
    "    'degree_product': False,             # Product of degrees\n",
    "    'degree_ratio': False,              # Ratio of degrees\n",
    "    'clustering_avg': False,           # Disable average clustering\n",
    "    'pagerank_avg': False,             # Disable average PageRank\n",
    "    \n",
    "    # === COMMUNITY FEATURES ===\n",
    "    'same_community': True,             # Same community indicator\n",
    "    'community_size_i': False,           # Community size of node i\n",
    "    'community_size_j': False,           # Community size of node j\n",
    "    'community_size_diff': False,        # Absolute difference in community sizes\n",
    "    'community_size_ratio': False,     # Disable community size ratio\n",
    "\n",
    "    # === COMMUNITY FEATURES (Resolution 0.5 - Bigger Communities) ===\n",
    "    'same_community_big': True,       # Same community indicator (big communities)\n",
    "    'community_size_i_big': False,     # Community size of node i (big communities)\n",
    "    'community_size_j_big': False,     # Community size of node j (big communities)\n",
    "    'community_size_diff_big': False,  # Absolute difference in community sizes (big communities)\n",
    "    'community_size_ratio_big': False, # Ratio of community sizes (big communities)\n",
    "}\n",
    "\n",
    "a = np.arange(0.6, 1.21, 0.2)\n",
    "b = np.arange(1.5, 10.01, 0.5)\n",
    "\n",
    "pairs = np.array(np.meshgrid(a, b)).T.reshape(-1, 2)\n",
    "\n",
    "mixed_results = test_community_resolutions(feature_config=custom_config, resolution_pairs=pairs)\n",
    "df_mixed_results = analyze_results(mixed_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate predictions with current configuration\n",
    "clf, test_features = generate_predictions(custom_config, 'predictions_with_relcomm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Leakage Prevention\n",
    "**IMPORTANT**: Metrics must be computed only on training data to prevent data leakage. The framework automatically handles this correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Understanding data leakage prevention\n",
    "print(\"=== Data Leakage Prevention Example ===\")\n",
    "\n",
    "# CORRECT: In cross-validation, metrics are computed only on training graph\n",
    "print(\"✓ Cross-validation: Metrics computed on G_train (training edges only)\")\n",
    "print(\"✓ No data leakage: Validation edges never used for metric computation\")\n",
    "\n",
    "# CORRECT: For final submission, metrics computed on full training graph\n",
    "print(\"✓ Final submission: Metrics computed on G (all training edges)\")\n",
    "print(\"✓ No data leakage: Test data never seen during training\")\n",
    "\n",
    "# Example: Extract features for a specific node pair (using full graph for demo)\n",
    "node_i, node_j = 1, 2\n",
    "features, feature_names = get_features(G, node_i, node_j, FEATURE_CONFIG)\n",
    "print(f\"Features for nodes ({node_i}, {node_j}): {len(features)} features\")\n",
    "print(f\"Feature names: {feature_names[:5]}...\")  # Show first 5 feature names\n",
    "\n",
    "print(\"\\n=== Key Points ===\")\n",
    "print(\"1. Cross-validation: Metrics computed on training fold only\")\n",
    "print(\"2. Final submission: Metrics computed on all training data\")\n",
    "print(\"3. Test data: Never used for metric computation\")\n",
    "print(\"4. Framework: Automatically prevents data leakage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Leakage Prevention\n",
    "\n",
    "### The Problem\n",
    "In link prediction, we must be careful about **data leakage**:\n",
    "- **Training data**: Known edges used to train the model\n",
    "- **Validation data**: Known edges used to evaluate the model (held out during training)\n",
    "- **Test data**: Unknown edges we want to predict\n",
    "\n",
    "### The Risk\n",
    "If we compute graph metrics (PageRank, clustering, communities) on the **full graph** including validation/test edges, we're essentially using future information to predict the past.\n",
    "\n",
    "### The Solution\n",
    "1. **Cross-validation**: Compute metrics only on the training fold (`G_train`)\n",
    "2. **Final submission**: Compute metrics on all training data (`G`) - this is correct because we're not evaluating anymore\n",
    "3. **Test data**: Never used for metric computation\n",
    "\n",
    "### How Our Framework Handles This\n",
    "- `test_single_configuration()`: Uses `G_train` for each fold\n",
    "- `generate_predictions()`: Uses `G` (all training data) for final model\n",
    "- `precompute_metrics()`: Takes the appropriate graph as input\n",
    "- `get_features()`: Uses precomputed metrics or computes on-the-fly\n",
    "\n",
    "This ensures **no data leakage** while maintaining **good performance**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use This Framework\n",
    "\n",
    "### 1. **Individual Feature Control**\n",
    "Each feature can be individually enabled/disabled by setting `True`/`False` in `FEATURE_CONFIG`:\n",
    "- `attribute_i`: Individual attribute value for node i\n",
    "- `degree_i`: Degree of node i\n",
    "- `clustering_i`: Clustering coefficient of node i\n",
    "- `common_neighbors`: Number of common neighbors\n",
    "- `jaccard_coefficient`: Jaccard coefficient\n",
    "- And many more...\n",
    "\n",
    "### 2. **Individual Feature Testing**\n",
    "Use `test_individual_features()` to test each feature separately and identify the most important ones.\n",
    "\n",
    "### 3. **Feature Group Testing**\n",
    "Use `test_feature_groups()` to test logical feature groups and their combinations.\n",
    "\n",
    "### 4. **Custom Configuration**\n",
    "Create your own configuration by modifying individual features in `FEATURE_CONFIG`.\n",
    "\n",
    "### 5. **Best Configuration**\n",
    "After finding the best individual features, use `generate_predictions()` to create your final submission.\n",
    "\n",
    "### 6. **Feature Categories**\n",
    "Features are organized into logical categories:\n",
    "- **Attribute features**: Individual values and equality indicators\n",
    "- **Basic node features**: Degree, clustering, PageRank for each node\n",
    "- **Neighborhood features**: Common neighbors, similarity measures\n",
    "- **Derived features**: Mathematical combinations of basic features\n",
    "- **Community features (Small)**: Community-based indicators and sizes at resolution 1.0\n",
    "- **Community features (Big)**: Community-based indicators and sizes at resolution 0.5\n",
    "\n",
    "### 7. **Dual Community Features**\n",
    "The framework now supports **two different community resolutions**:\n",
    "- **Small communities** (resolution 1.0): More granular, smaller communities\n",
    "- **Big communities** (resolution 0.5): Less granular, larger communities\n",
    "\n",
    "This allows you to capture both local community structure (small) and global community structure (big) simultaneously.\n",
    "\n",
    "### 8. **Community Resolution Testing**\n",
    "- `test_community_resolutions()`: Test different resolution combinations\n",
    "- `compare_community_features()`: Compare small vs big vs both community features\n",
    "- Resolution pairs: Explore combinations like (0.3, 0.8), (0.5, 1.5), etc.\n",
    "\n",
    "This granular control allows you to optimize performance by selecting only the most effective individual features and community resolution combinations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
